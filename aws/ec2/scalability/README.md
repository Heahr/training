## AWS EC2 Scalability

##### AWS EC2를 이용해 급변하는 인스턴스의 규모를 유연하게 변경해보자.  

#### Scalability를 보장해야 하는 이유  

앞서 AWS EC2 Basic에서는 간단한 실습을 진행했다. 이 문서에서는 앞선 문서와는 다르게 AWS EC2를 실습보다 이론적으로 정리하게 될 것이다.  

클라우드 컴퓨팅의 핵심적인 특징은 '가상화'와 '종량제'이다. AWS EC2가 가장 대표적으로 가상화와 종량제를 제공하고 있기 때문에 이를 통해 자세하게 살펴보자.  

일반적으로 '가상머신'이라고 하면 논리적으로는 컴퓨터와 똑같이 동작하지만, 물리적으로는 존재하지 않는 기계라고 설명한다. 여기서의 물리적은 사용자 입장에서의 물리적인 공간을 이야기하며, 실제로는 물리적으로도 장비가 존재하고 있다.  

가상머신을 사용한다고 하면, 운영체제에 가상머신이라는 소프트웨어로 만든 기계를 설치해 이를 사용하는 것을 말한다. 실제로는 하나의 운영체제가 동작하지만, 가상머신 위에 여러 운영체제를 설치해 사용자의 입장에서는 여러 운영체제를 사용한다고 느낄 수 있다는 것이다.  

현재의 클라우드 컴퓨팅의 가장 주요 고객은 '기업'이다. 그렇기 때문에 주요 사용처는 두 가지로 나눌 수 있다.  

스타트업과 같이 방문 고객이 적은 경우 성능은 다소 떨어지지만, 저렴한 컴퓨터를 사용하는 경우와 대기업과 같이 방문 고객이 많고, 아주 강력한 컴퓨터가 필요한 경우가 그 예이다.  

일반적으로 성능을 이렇게 구분하는 이유는 Scalability를 제공하기 위함이다. 우리의 고객은 고정되어있지 않고, 유동적이기 때문에 컴퓨터의 성능을 유동적으로 조정한다면 완벽할 것이다.  

클라우드 컴퓨터를 사용하기 이전의 비즈니스에서 Scalability를 보장하는 방법은 물리적으로 직접 관리하는 방법이었다. 비즈니스는 항상 성장하지 않기 때문에 물리적으로 컴퓨터의 스케일을 늘리는 일은 기업의 입장에서는 부담스러울 수밖에 없다. 그렇기 때문에 클라우드 컴퓨터를 사용하는 것이 효율적이다.  

#### Stress Test  

Scale Up이라고 하면, 컴퓨터를 Upgrade하는 것이라고 보면 된다. 우리 회사의 트래픽이 증가하면 Scale Up을 하고, 감소하면 Scale Down을 하면 되는 것이다.  

Scale Up & Down을 테스트하기 위해 필요한 인스턴스는 2개이다. 한쪽에서는 웹 서버를 구동시키고, 다른 한쪽에서는 구동되어 있는 웹 서버에 계속적으로 접속하는 방법이다.  

이는 'Stress Test'라고 하며, 웹에 국한된 이야기가 아닌 컴퓨터를 사용하는 모든 분야에 적용할 수 있다. User와 Server로 구성하며, Server에 해당하는 컴퓨터는 Scale을 조절해가며 User의 요구를 소화해내는 과정이다.  

수동으로는 사용자가 아무리 접속해도 부하가 일어나지 않는다. 그렇기 때문에 apache2-utils를 설치해 ab를 사용해 부하를 발생시킬 것이다.  

```
User$ sudo apt-get update  
User$ sudo apt-get install apache-utils  
// apache-utils를 설치한다  

...
Server$ top
// 이 과정에서 우리의 서버는 현재 프로세스의 상황을 지켜보도록 하자  

User$ ab 
// 사용법을 확인하고 이를 통해 부하를 발생시켜 보자  

User$ ab -n 400 -c 1 http://웹 서버 주소  
// -n: 접속하고자 하는 유저는 400명, 동시 접속은 최대 1명, 즉 하지 않겠다  
// 이제 서버의 프로세스 변화를 살펴보자  
```

이제 ab의 결과를 살펴보자.  

* Concurrency Level: 동시 접속  
* Time taken for tests: 총 소요 시간, 즉 모든 사용자가 최선을 다해 접속했을 때의 소요시간을 의미한다.  
* Complete requests: 성공한 요청  
* Failed requests: 실패한 요청  
* Requests per second: 초당 처리 속도, 즉 우리의 인스턴스가 초당 수행할 수 있는 처리의 속도를 의미한다.  
* Time per request: 개별 처리 속도, 즉 평균적으로 하나의 유저에 대한 처리 속도를 의미한다.  
  
이제 동시접속자의 수를 늘려가며 실습을 진행해 어떠한 점이 달라졌는지를 살펴보도록 하자.  

필자의 경우에는 상대적으로 총 소요시간은 줄어들었지만, 개별 처리 속도가 증가한 것을 확연히 느낄 수 있었다. 이것을 좀 더 느끼기 위해서는 ab를 실행하면서 직접적을 웹 서버 주소로 접속해보는 것이다.  


#### 참고자료  
[생활코딩 - AWS EC2 Scalability](https://opentutorials.org/course/2717/11294)  


